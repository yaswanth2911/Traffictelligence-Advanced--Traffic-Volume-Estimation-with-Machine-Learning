{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fbdda52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Traffic Volume Prediction Script ---\n",
      "‚úÖ Data loaded successfully from 'traffic volume.csv'. Shape: (48204, 8)\n",
      "First 5 rows of the dataset:\n",
      "  holiday    temp  rain  snow weather        date      Time  traffic_volume\n",
      "0     NaN  288.28   0.0   0.0  Clouds  02-10-2012  09:00:00            5545\n",
      "1     NaN  289.36   0.0   0.0  Clouds  02-10-2012  10:00:00            4516\n",
      "2     NaN  289.58   0.0   0.0  Clouds  02-10-2012  11:00:00            4767\n",
      "3     NaN  290.13   0.0   0.0  Clouds  02-10-2012  12:00:00            5026\n",
      "4     NaN  291.14   0.0   0.0  Clouds  02-10-2012  13:00:00            4918\n",
      "\n",
      "--- Handling Missing Values ---\n",
      "  - Filled missing values in 'temp' with its mean.\n",
      "  - Filled missing values in 'rain' with its mean.\n",
      "  - Filled missing values in 'snow' with its mean.\n",
      "  - Filled missing values in 'weather' with its mode: 'Clouds'.\n",
      "\n",
      "Missing values after preprocessing:\n",
      "holiday           48143\n",
      "temp                  0\n",
      "rain                  0\n",
      "snow                  0\n",
      "weather               0\n",
      "date                  0\n",
      "Time                  0\n",
      "traffic_volume        0\n",
      "dtype: int64\n",
      "\n",
      "--- Feature Engineering: Extracting Date & Time Components ---\n",
      "  - Converted 'day' to int.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yaswa\\AppData\\Local\\Temp\\ipykernel_11796\\3148992180.py:36: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data[col].fillna(data[col].mean(), inplace=True)\n",
      "C:\\Users\\yaswa\\AppData\\Local\\Temp\\ipykernel_11796\\3148992180.py:42: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['weather'].fillna(mode_weather, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  - Converted 'month' to int.\n",
      "  - Converted 'year' to int.\n",
      "  - Converted 'hours' to int.\n",
      "  - Converted 'minutes' to int.\n",
      "  - Converted 'seconds' to int.\n",
      "\n",
      "Data after feature engineering (first 5 rows):\n",
      "  holiday    temp  rain  snow weather  traffic_volume  day  month  year  \\\n",
      "0     NaN  288.28   0.0   0.0  Clouds            5545    2     10  2012   \n",
      "1     NaN  289.36   0.0   0.0  Clouds            4516    2     10  2012   \n",
      "2     NaN  289.58   0.0   0.0  Clouds            4767    2     10  2012   \n",
      "3     NaN  290.13   0.0   0.0  Clouds            5026    2     10  2012   \n",
      "4     NaN  291.14   0.0   0.0  Clouds            4918    2     10  2012   \n",
      "\n",
      "   hours  minutes  seconds  \n",
      "0      9        0        0  \n",
      "1     10        0        0  \n",
      "2     11        0        0  \n",
      "3     12        0        0  \n",
      "4     13        0        0  \n",
      "\n",
      "--- Encoding Categorical Features ---\n",
      "  - 'holiday' and 'weather' columns have been label encoded.\n",
      "  - Holiday mapping: {'Christmas Day': np.int64(0), 'Columbus Day': np.int64(1), 'Independence Day': np.int64(2), 'Labor Day': np.int64(3), 'Martin Luther King Jr Day': np.int64(4), 'Memorial Day': np.int64(5), 'New Years Day': np.int64(6), 'State Fair': np.int64(7), 'Thanksgiving Day': np.int64(8), 'Veterans Day': np.int64(9), 'Washingtons Birthday': np.int64(10), nan: np.int64(11)}\n",
      "  - Weather mapping: {'Clear': np.int64(0), 'Clouds': np.int64(1), 'Drizzle': np.int64(2), 'Fog': np.int64(3), 'Haze': np.int64(4), 'Mist': np.int64(5), 'Rain': np.int64(6), 'Smoke': np.int64(7), 'Snow': np.int64(8), 'Squall': np.int64(9), 'Thunderstorm': np.int64(10)}\n",
      "  - Original 'holiday' and 'weather' columns dropped.\n",
      "\n",
      "‚úÖ Features (X) shape: (48204, 11), Target (y) shape: (48204,)\n",
      "Features used for training:\n",
      "['temp', 'rain', 'snow', 'day', 'month', 'year', 'hours', 'minutes', 'seconds', 'holiday_encoded', 'weather_encoded']\n",
      "\n",
      "--- Scaling Features ---\n",
      "  - Features scaled using StandardScaler.\n",
      "Scaled features (first 5 rows):\n",
      "       temp      rain      snow       day    month      year     hours  \\\n",
      "0  0.530485 -0.007463 -0.027235 -1.574903  1.02758 -1.855294 -0.345548   \n",
      "1  0.611467 -0.007463 -0.027235 -1.574903  1.02758 -1.855294 -0.201459   \n",
      "2  0.627964 -0.007463 -0.027235 -1.574903  1.02758 -1.855294 -0.057371   \n",
      "3  0.669205 -0.007463 -0.027235 -1.574903  1.02758 -1.855294  0.086718   \n",
      "4  0.744939 -0.007463 -0.027235 -1.574903  1.02758 -1.855294  0.230807   \n",
      "\n",
      "   minutes  seconds  holiday_encoded  weather_encoded  \n",
      "0      0.0      0.0         0.031687        -0.566452  \n",
      "1      0.0      0.0         0.031687        -0.566452  \n",
      "2      0.0      0.0         0.031687        -0.566452  \n",
      "3      0.0      0.0         0.031687        -0.566452  \n",
      "4      0.0      0.0         0.031687        -0.566452  \n",
      "\n",
      "--- Splitting Data into Training and Testing Sets (20.0% test size) ---\n",
      "  - X_train shape: (38563, 11), y_train shape: (38563,)\n",
      "  - X_test shape: (9641, 11), y_test shape: (9641,)\n",
      "\n",
      "--- Training Gradient Boosting Regressor Model ---\n",
      "‚úÖ Model training complete.\n",
      "\n",
      "--- Evaluating Model Performance ---\n",
      "  - R2 Score (Test Set): 0.7937\n",
      "  - Mean Squared Error (Test Set): 815716.1151\n",
      "  - Root Mean Squared Error (Test Set): 903.1700\n",
      "\n",
      "--- Saving Trained Model and Preprocessing Components ---\n",
      "‚úÖ Model saved to 'traffic_model.joblib'\n",
      "‚úÖ Scaler saved to 'scaler.joblib'\n",
      "‚úÖ Encoders saved to 'encoders.joblib'\n",
      "\n",
      "--- Demonstration: Loading Saved Components and Making a Prediction ---\n",
      "\n",
      "Predicting for example new data:\n",
      "{'temp': 22.5, 'rain': 0.1, 'snow': 0.0, 'day': 20, 'month': 7, 'year': 2025, 'hours': 17, 'minutes': 45, 'seconds': 0, 'holiday': 'None', 'weather': 'Clear'}\n",
      "  - Model, scaler, and encoders loaded successfully for prediction.\n",
      "‚ùå An error occurred during prediction: y contains previously unseen labels: 'None'\n",
      "\n",
      "--- Script Finished ---\n"
     ]
    }
   ],
   "source": [
    "# üì¶ Essential Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib  # ‚úÖ For efficient saving/loading of models and transformers\n",
    "\n",
    "# --- Configuration ---\n",
    "DATA_PATH = \"traffic volume.csv\"\n",
    "MODEL_SAVE_PATH = 'traffic_model.joblib'\n",
    "ENCODERS_SAVE_PATH = 'encoders.joblib'\n",
    "SCALER_SAVE_PATH = 'scaler.joblib'\n",
    "TEST_SIZE_RATIO = 0.2\n",
    "RANDOM_STATE_SEED = 42\n",
    "\n",
    "print(\"--- Starting Traffic Volume Prediction Script ---\")\n",
    "\n",
    "# üì• Step 1: Load Data\n",
    "try:\n",
    "    data = pd.read_csv(DATA_PATH)\n",
    "    print(f\"‚úÖ Data loaded successfully from '{DATA_PATH}'. Shape: {data.shape}\")\n",
    "    print(\"First 5 rows of the dataset:\")\n",
    "    print(data.head())\n",
    "except FileNotFoundError:\n",
    "    print(f\"‚ùå Error: The file '{DATA_PATH}' was not found. Please ensure it's in the correct directory.\")\n",
    "    exit() # Exit if data cannot be loaded\n",
    "\n",
    "# üßπ Step 2: Clean & Preprocess Missing Values\n",
    "print(\"\\n--- Handling Missing Values ---\")\n",
    "# Fill numerical missing values with their mean\n",
    "numerical_cols = ['temp', 'rain', 'snow']\n",
    "for col in numerical_cols:\n",
    "    if data[col].isnull().any():\n",
    "        data[col].fillna(data[col].mean(), inplace=True)\n",
    "        print(f\"  - Filled missing values in '{col}' with its mean.\")\n",
    "\n",
    "# Fill categorical missing values in 'weather' with the most frequent value (mode)\n",
    "if data['weather'].isnull().any():\n",
    "    mode_weather = data['weather'].mode()[0]\n",
    "    data['weather'].fillna(mode_weather, inplace=True)\n",
    "    print(f\"  - Filled missing values in 'weather' with its mode: '{mode_weather}'.\")\n",
    "\n",
    "print(\"\\nMissing values after preprocessing:\")\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# üïê Step 3: Feature Engineering - Extract Date & Time Components\n",
    "print(\"\\n--- Feature Engineering: Extracting Date & Time Components ---\")\n",
    "# Split 'date' into day, month, year\n",
    "data[['day', 'month', 'year']] = data['date'].str.split('-', expand=True)\n",
    "# Split 'Time' into hours, minutes, seconds\n",
    "data[['hours', 'minutes', 'seconds']] = data['Time'].str.split(':', expand=True)\n",
    "\n",
    "# Drop original 'date' and 'Time' columns as they've been transformed\n",
    "data.drop(columns=['date', 'Time'], inplace=True)\n",
    "\n",
    "# Convert newly created time columns to integer type\n",
    "cols_to_convert_to_int = ['day', 'month', 'year', 'hours', 'minutes', 'seconds']\n",
    "for col in cols_to_convert_to_int:\n",
    "    data[col] = pd.to_numeric(data[col], errors='coerce') # Coerce errors to NaN then fill\n",
    "    if data[col].isnull().any():\n",
    "        # Handle cases where conversion might result in NaN (e.g., if original string wasn't a valid number)\n",
    "        data[col].fillna(data[col].mode()[0], inplace=True) # Fill with mode for safety\n",
    "        print(f\"  - Converted '{col}' to int and handled potential NaNs from conversion.\")\n",
    "    else:\n",
    "        print(f\"  - Converted '{col}' to int.\")\n",
    "\n",
    "print(\"\\nData after feature engineering (first 5 rows):\")\n",
    "print(data.head())\n",
    "\n",
    "# üè∑Ô∏è Step 4: Encode Categorical Features\n",
    "print(\"\\n--- Encoding Categorical Features ---\")\n",
    "# Initialize LabelEncoders for 'holiday' and 'weather'\n",
    "le_holiday = LabelEncoder()\n",
    "le_weather = LabelEncoder()\n",
    "\n",
    "# Apply Label Encoding\n",
    "data['holiday_encoded'] = le_holiday.fit_transform(data['holiday'])\n",
    "data['weather_encoded'] = le_weather.fit_transform(data['weather'])\n",
    "\n",
    "# Store encoders in a dictionary for saving\n",
    "encoders = {\n",
    "    'holiday_encoder': le_holiday,\n",
    "    'weather_encoder': le_weather,\n",
    "    'holiday_original_map': dict(zip(le_holiday.classes_, le_holiday.transform(le_holiday.classes_))),\n",
    "    'weather_original_map': dict(zip(le_weather.classes_, le_weather.transform(le_weather.classes_)))\n",
    "}\n",
    "print(\"  - 'holiday' and 'weather' columns have been label encoded.\")\n",
    "print(f\"  - Holiday mapping: {encoders['holiday_original_map']}\")\n",
    "print(f\"  - Weather mapping: {encoders['weather_original_map']}\")\n",
    "\n",
    "# Drop original categorical columns\n",
    "data.drop(columns=['holiday', 'weather'], inplace=True)\n",
    "print(\"  - Original 'holiday' and 'weather' columns dropped.\")\n",
    "\n",
    "# üß™ Step 5: Define Features (X) and Target (y)\n",
    "y = data['traffic_volume']\n",
    "X = data.drop('traffic_volume', axis=1) # Drop the original target column\n",
    "\n",
    "print(f\"\\n‚úÖ Features (X) shape: {X.shape}, Target (y) shape: {y.shape}\")\n",
    "print(\"Features used for training:\")\n",
    "print(X.columns.tolist())\n",
    "\n",
    "# ‚öñÔ∏è Step 6: Scale Numerical Features\n",
    "print(\"\\n--- Scaling Features ---\")\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X) # Fit and transform X\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns) # Convert back to DataFrame for consistency\n",
    "\n",
    "print(\"  - Features scaled using StandardScaler.\")\n",
    "print(\"Scaled features (first 5 rows):\")\n",
    "print(X_scaled_df.head())\n",
    "\n",
    "# üîÄ Step 7: Train-Test Split\n",
    "print(f\"\\n--- Splitting Data into Training and Testing Sets ({TEST_SIZE_RATIO*100}% test size) ---\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled_df, y, test_size=TEST_SIZE_RATIO, random_state=RANDOM_STATE_SEED\n",
    ")\n",
    "print(f\"  - X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "print(f\"  - X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "\n",
    "# ‚úÖ Step 8: Train the Model (Using GradientBoostingRegressor as in your lightweight model section)\n",
    "print(\"\\n--- Training Gradient Boosting Regressor Model ---\")\n",
    "model = GradientBoostingRegressor(n_estimators=100, max_depth=3, random_state=RANDOM_STATE_SEED)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"‚úÖ Model training complete.\")\n",
    "\n",
    "# üìä Step 9: Evaluate the Model\n",
    "print(\"\\n--- Evaluating Model Performance ---\")\n",
    "y_pred = model.predict(X_test)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"  - R2 Score (Test Set): {r2:.4f}\")\n",
    "print(f\"  - Mean Squared Error (Test Set): {mse:.4f}\")\n",
    "print(f\"  - Root Mean Squared Error (Test Set): {rmse:.4f}\")\n",
    "\n",
    "# --- Optional: Model Comparison (as per your original code) ---\n",
    "# If you want to compare multiple models, uncomment and adapt this section:\n",
    "# print(\"\\n--- Optional: Comparing Multiple Models (using original code logic) ---\")\n",
    "# from sklearn import linear_model, tree, ensemble, svm\n",
    "# import xgboost\n",
    "# lin_reg = linear_model.LinearRegression()\n",
    "# Dtree = tree.DecisionTreeRegressor(random_state=RANDOM_STATE_SEED)\n",
    "# Rand = ensemble.RandomForestRegressor(random_state=RANDOM_STATE_SEED)\n",
    "# svr = svm.SVR()\n",
    "# XGB = xgboost.XGBRegressor(random_state=RANDOM_STATE_SEED)\n",
    "\n",
    "# models_list = {'Linear': lin_reg, 'Decision Tree': Dtree, 'Random Forest': Rand, 'SVR': svr, 'XGBoost': XGB}\n",
    "# for name, algo in models_list.items():\n",
    "#     print(f\"  - Training {name}...\")\n",
    "#     algo.fit(X_train, y_train)\n",
    "#     preds = algo.predict(X_test)\n",
    "#     r2_val = r2_score(y_test, preds)\n",
    "#     mse_val = mean_squared_error(y_test, preds)\n",
    "#     print(f\"    - {name} R2 Score: {r2_val:.4f}, MSE: {mse_val:.4f}\")\n",
    "\n",
    "# üíæ Step 10: Save Trained Model, Scaler, and Encoders\n",
    "print(\"\\n--- Saving Trained Model and Preprocessing Components ---\")\n",
    "joblib.dump(model, MODEL_SAVE_PATH, compress=3)\n",
    "joblib.dump(scaler, SCALER_SAVE_PATH)\n",
    "joblib.dump(encoders, ENCODERS_SAVE_PATH) # Save the dictionary of encoders\n",
    "\n",
    "print(f\"‚úÖ Model saved to '{MODEL_SAVE_PATH}'\")\n",
    "print(f\"‚úÖ Scaler saved to '{SCALER_SAVE_PATH}'\")\n",
    "print(f\"‚úÖ Encoders saved to '{ENCODERS_SAVE_PATH}'\")\n",
    "\n",
    "\n",
    "# --- Demonstration of Loading and Predicting ---\n",
    "print(\"\\n--- Demonstration: Loading Saved Components and Making a Prediction ---\")\n",
    "\n",
    "def predict_traffic_volume(\n",
    "    input_data: dict,\n",
    "    model_path: str = MODEL_SAVE_PATH,\n",
    "    scaler_path: str = SCALER_SAVE_PATH,\n",
    "    encoders_path: str = ENCODERS_SAVE_PATH\n",
    ") -> float:\n",
    "    \"\"\"\n",
    "    Loads the saved model, scaler, and encoders, and predicts traffic volume\n",
    "    for a single new input data point.\n",
    "\n",
    "    Args:\n",
    "        input_data (dict): A dictionary containing input features, e.g.:\n",
    "                           {\n",
    "                               'temp': 20.5, 'rain': 0.0, 'snow': 0.0,\n",
    "                               'day': 15, 'month': 6, 'year': 2024,\n",
    "                               'hours': 10, 'minutes': 30, 'seconds': 0,\n",
    "                               'holiday': 'None', 'weather': 'Clouds'\n",
    "                           }\n",
    "        model_path (str): Path to the saved model.\n",
    "        scaler_path (str): Path to the saved scaler.\n",
    "        encoders_path (str): Path to the saved encoders.\n",
    "\n",
    "    Returns:\n",
    "        float: Predicted traffic volume.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Load components\n",
    "        loaded_model = joblib.load(model_path)\n",
    "        loaded_scaler = joblib.load(scaler_path)\n",
    "        loaded_encoders = joblib.load(encoders_path)\n",
    "        print(\"  - Model, scaler, and encoders loaded successfully for prediction.\")\n",
    "\n",
    "        # Convert input_data to DataFrame\n",
    "        input_df = pd.DataFrame([input_data])\n",
    "\n",
    "        # Apply Label Encoding using the loaded encoders\n",
    "        input_df['holiday_encoded'] = loaded_encoders['holiday_encoder'].transform(input_df['holiday'])\n",
    "        input_df['weather_encoded'] = loaded_encoders['weather_encoder'].transform(input_df['weather'])\n",
    "        input_df.drop(columns=['holiday', 'weather'], inplace=True) # Drop original columns\n",
    "\n",
    "        # Ensure columns are in the same order as during training\n",
    "        # Get column names from the scaler (or from X.columns directly if you save them explicitly)\n",
    "        # Assuming X_scaled_df had the correct order\n",
    "        # For a robust solution, you might save X.columns during training.\n",
    "        # For now, let's derive it from the scaler's features_in_ or reconstruct\n",
    "        # For simplicity, let's assume the columns are in the same order as X_train\n",
    "        # from the training script. This is a common point of failure if not handled precisely.\n",
    "        # A safer way: `loaded_model.feature_names_in_` if available or save `X.columns`\n",
    "        # during training.\n",
    "\n",
    "        # Reorder columns to match the training data's feature order\n",
    "        # This is a crucial step to avoid prediction errors due to misaligned features\n",
    "        training_features_order = X.columns.tolist() # X from training script has the original order before scaling\n",
    "\n",
    "        # Create a DataFrame for the single input, ensuring column order matches training\n",
    "        processed_input_df = input_df[['temp', 'rain', 'snow', 'day', 'month', 'year',\n",
    "                                       'hours', 'minutes', 'seconds',\n",
    "                                       'holiday_encoded', 'weather_encoded']]\n",
    "\n",
    "        # Scale the input data using the loaded scaler\n",
    "        scaled_input = loaded_scaler.transform(processed_input_df)\n",
    "\n",
    "        # Make prediction\n",
    "        prediction = loaded_model.predict(scaled_input)\n",
    "        return prediction[0]\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå An error occurred during prediction: {e}\")\n",
    "        return -1 # Return a sentinel value for error\n",
    "\n",
    "# Example usage of the prediction function\n",
    "example_new_data = {\n",
    "    'temp': 22.5,\n",
    "    'rain': 0.1,\n",
    "    'snow': 0.0,\n",
    "    'day': 20,\n",
    "    'month': 7,\n",
    "    'year': 2025,\n",
    "    'hours': 17,\n",
    "    'minutes': 45,\n",
    "    'seconds': 0,\n",
    "    'holiday': 'None',\n",
    "    'weather': 'Clear'\n",
    "}\n",
    "\n",
    "print(\"\\nPredicting for example new data:\")\n",
    "print(example_new_data)\n",
    "predicted_volume = predict_traffic_volume(example_new_data)\n",
    "if predicted_volume != -1:\n",
    "    print(f\"Predicted Traffic Volume: {predicted_volume:.2f}\")\n",
    "\n",
    "print(\"\\n--- Script Finished ---\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
